"""
Main Snakemake-based model fitting pipeline.
"""
import numpy as np

CHROMS = [f'chr{x}' for x in range(1, 23)]

# ---- load config file
name = config["name"]
nstarts = config["nstarts"]
nstarts_loo = config["nstarts_loo"]
nstarts_jackknife = config["nstarts_jackknife"]
mu = config.get("mu", None)
if mu == "free":
  mu = None
else:
  assert instance(mu, float), "mu must be 'free' or a float"
seqlens_file = config["seqlens_file"]
recmap_file = config["recmap_file"]
access_file = config["access_file"]
features_file = config["features_file"]
neut_file = config["neut_file"]
fasta_file = config["fasta_file"]
counts_dir = config["counts_dir"]
N = config["N"]
fit_rescaled = config["fit_rescaled"]
windows = [int(w) for w in config["windows"]]
blocksizes = config["blocksizes"]
njack_samples = config["num_jackknife_samples"]
pi0_bounds = config["pi0_bounds"]
mu_bounds = config["mu_bounds"]

## ------ created data
# name auto-generated
# Note: the B/B' maps can be reused across runs which 
# vary in data. The .. is because fits are run in subdirs
Bs_file = f"../bmaps/bmap_6x8grid_100000step_{N}N_{name}.pkl"
print(Bs_file)
# Note: the locally-rescaled B/B' maps are **fit specific**
# so in the fit subdirectory
Bs_file_rescaled = f"bmap_rescaled_{{window}}_6x8grid_100000step_{N}N_{name}.pkl"

# the data that goes into the likelihood model
model_data = [f'model_data_{w}.pkl' for w in windows]

# the data needed for all fits in this model
loo_results = []
jk_results = []
mle_results = []
mle_results_rescaled = []
boots_results = []
for window in windows:
  mle_results.append(f'fit_{window}/mle.pkl')
  if fit_rescaled:
      mle_results_rescaled.append(f'fit_{window}_rescaled/mle.pkl')
      # chromosome-level LOO for R2, etc
      for chrom in CHROMS:
          loo = f"fit_{window}_rescaled/loo_chrom/loo_{chrom}.pkl"
          loo_results.append(loo)
      # block-level jackknife
      for blocksize in blocksizes:
          for frac in np.linspace(0, 1, njack_samples)[:-1]:
              frac = np.round(frac, 5)
              jk_results.append(f'fit_{window}_rescaled/jackknife/{blocksize}/jackknife_{frac}.pkl')
 
  # chromosome-level LOO for R2, etc
  for chrom in CHROMS:
      loo = f"fit_{window}/loo_chrom/loo_{chrom}.pkl"
      loo_results.append(loo)
  # block-level jackknife
  for blocksize in blocksizes:
      # this is a very close approximation to the block-jackknife, 
      # were samples at evenly spaced fraction positions are taken
      # and left out; this prevents us from having to know the number
      # of blocks a priori, which is easier when pushing computation to the
      # cluster
      # non-inclusive, otherwise index error
      for frac in np.linspace(0, 1, njack_samples)[:-1]:
          frac = np.round(frac, 5)
          jk_results.append(f'fit_{window}/jackknife/{blocksize}/jackknife_{frac}.pkl')
    

## ------- rules
rule bmap:
  input: seqlens_file=seqlens_file,
         recmap=recmap_file,
         features=features_file
  output: pkl_b_file="../bmaps/bmap_{grid_str,[0-9x]+}grid_{step}step_{N}N_{name}.pkl"
  benchmark: "benchmarks/bmap_{grid_str,[0-9x]+}grid_{step}step_{N}N_{name}.txt"
  resources:
    mem_mb=200000,
    time_min=4320,
    threads=40
  shell:
    """
    bgspy calcb \
      --recmap {input.recmap} --annot {input.features} \
      --seqlens {input.seqlens_file} --g '{wildcards.grid_str}' \
      --output {output} --popsize {wildcards.N} \
      --ncores {resources.threads} --ncores-Bp {resources.threads} \
      --step {wildcards.step}
    """

rule save_data:
  # only get the data, e.g. for testing, for this model
  input: seqlens=seqlens_file, recmap_file=recmap_file,
         access_file=access_file, fasta_file=fasta_file,
         neut_file=neut_file, counts_dir=counts_dir,
         bs_file=Bs_file
  output: 'model_data_{window,\d+}.pkl'
  benchmark: "benchmarks/data_{window}.txt"
  params: name=name
  resources:
    mem_mb=50000,
    time_min=300,
  shell:
    """
    mkdir -p {params.name}
    bgspy data --seqlens {input.seqlens} --recmap {input.recmap_file} \
      --counts-dir {input.counts_dir} --neutral {input.neut_file} \
      --access {input.access_file} --bs-file {input.bs_file} \
      --window {wildcards.window} \
      --fasta {input.fasta_file} \
      --output {output[0]}
    """

rule fit:
  input: 'model_data_{window}.pkl'
  output: 'fit_{window,\d+}/mle.pkl'
  params: nstarts=nstarts, mu=mu, name=name, pi0_bounds=pi0_bounds, mu_bounds=mu_bounds
  resources:
    mem_mb=50000,
    time_min=480,
    threads=40
  benchmark: "benchmarks/fit_{window}.txt"
  shell:
    """
    mkdir -p {params.name}
    bgspy fit \
      --pi0-bounds {params.pi0_bounds} --mu-bounds {params.mu_bounds} \
      --mu {params.mu} \
      --data {input[0]} \
      --ncores {resources.threads} --nstarts {params.nstarts} \
      --mu {params.mu} \
      --output {output[0]}
    """

## NOTE: for jackknife and loo, we don't need to extract window
# information from the window wildcard, so we just blog over both
# so these rules work for initial and rescaled fits
rule block_jackknife:
  # note that this doesn't actually require fit object, but 
  # I prefer that gets calculated first
  input: data='model_data_{window_rescaled}.pkl', fit='fit_{window_rescaled}/mle.pkl'
  output: 'fit_{window_rescaled}/jackknife/{blocksize}/jackknife_{frac}.pkl'
  params: nstarts=nstarts_jackknife
  resources:
    mem_mb=10000,
    time_min=300,
    threads=40
  shell:
    """
    bgspy jackblock \
      --blockwidth {wildcards.blocksize} \
      --data {input.data} \
      --output {output[0]} \
      --blockfrac {wildcards.frac} \
      --ncores {resources.threads} --nstarts {params.nstarts}
    """


rule loo_chrom:
  # note that this doesn't actually require fit object, but 
  # I prefer that gets calculated first
  input: data='model_data_{window_rescaled}.pkl', fit='fit_{window_rescaled}/mle.pkl'
  output: 'fit_{window_rescaled}/loo_chrom/loo_{chrom}.pkl'
  params: nstarts=nstarts_loo
  resources:
    mem_mb=10000,
    time_min=300,
    threads=40
  shell:
    """
    bgspy loo \
      --data {input.data} \
      --output {output[0]} \
      --chrom {wildcards.chrom} \
      --ncores {resources.threads} --nstarts {params.nstarts}
    """

# ----- locally-rescaled fits -----
rule bmap_rescale:
  input: seqlens_file=seqlens_file,
         recmap=recmap_file,
         features=features_file,
         fit='fit_{window}/mle.pkl',
         b=Bs_file
  output: pkl_b_file="bmap_rescaled_{window,\d+}_{grid_str,[0-9x]+}grid_{step}step_{N}N_{name}.pkl"
  resources:
    mem_mb=200000,
    time_min=4320,
    threads=40
  shell:
    """
    bgspy calcb \
      --recmap {input.recmap} --annot {input.features} \
      --seqlens {input.seqlens_file} --g '{wildcards.grid_str}' \
      --output {output} --popsize {wildcards.N} \
      --ncores {resources.threads} --ncores-Bp {resources.threads} \
      --step {wildcards.step} \
      --rescale-fit {input.fit} --only-Bp \
      --rescale-Bp-file {input.b}
    """

rule save_data_rescale:
  input: seqlens=seqlens_file, recmap_file=recmap_file,
         access_file=access_file, fasta_file=fasta_file,
         neut_file=neut_file, counts_dir=counts_dir,
         bs_file=Bs_file_rescaled
  output: 'model_data_{window,\d+}_rescaled.pkl'
  params: name=name
  resources:
    mem_mb=20000,
    time_min=300
  shell:
    """
    mkdir -p {params.name}
    bgspy data --seqlens {input.seqlens} --recmap {input.recmap_file} \
      --counts-dir {input.counts_dir} --neutral {input.neut_file} \
      --access {input.access_file} --bs-file {input.bs_file} \
      --window {wildcards.window} \
      --fasta {input.fasta_file} \
      --output {output[0]}
    """

rule fit_rescaled:
  input: 'model_data_{window,\d+}_rescaled.pkl'
  output: 'fit_{window,\d+}_rescaled/mle.pkl'
  params: nstarts=nstarts, mu=mu, name=name, pi0_bounds=pi0_bounds, mu_bounds=mu_bounds
  benchmark: "benchmarks/fit_{window}_rescaled.txt"
  resources:
    mem_mb=50000,
    time_min=480,
    threads=40
  shell:
    """
    mkdir -p {params.name}
    bgspy fit \
      --pi0-bounds {params.pi0-bounds} --mu_bounds {params.mu_bounds} \
      --mu {params.mu}
      --data {input[0]} \
      --ncores {resources.threads} --nstarts {params.nstarts} \
      --output {output[0]} --only-Bp
    """

## ----- CLI rules 
rule data:
  input: model_data

rule mle:
  input: mle_results

rule jackknife:
  input: mle_results, jk_results

rule loo:
  input: mle_results, loo_results

rule rescaled:
  input: mle_results_rescaled

rule all:
  input: model_data, mle_results, loo_results, jk_results, mle_results_rescaled


