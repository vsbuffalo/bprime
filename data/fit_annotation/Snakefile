import numpy as np
import pandas as pd
from bgspy.utils import load_seqlens, load_cadd_bed_scores
from bgspy.utils import quantize_track, phred

AUTOS = list(range(1, 23))
AUTOSEX = AUTOS + ['X', 'Y']

## ------ Human genome data

genome = ["hg38.fa.gz", "hg38_seqlens.tsv"]

rule hg38:
  # fixes chromosome labels to start with 'chr'
  output: "hg38.fa.gz"
  shell:
    """
    curl http://ftp.ensembl.org/pub/release-107/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz | \
      zcat | sed 's/^>/>chr/' | gzip > {output}
    """

## only keep autosomes
rule seqlens:
  input: "hg38.fa.gz"
  output: "hg38_seqlens.tsv"
  shell:
    """
      bioawk -cfastx '{{ print $name,length($seq) }}' hg38.fa.gz | \
      grep -P '^chr[0-9X]+' |  \
      sort  --version-sort -k 1,1 -k2,2n > {output}
    """

## ----- Human Recombination Maps
rule decode_2019_map:
   output: "aau1043_datas3.gz"
   shell:
      """
      wget -O {output} https://www.science.org/doi/suppl/10.1126/science.aau1043/suppl_file/aau1043_datas3.gz
      #wget -O {output} https://www-science-org.libproxy.berkeley.edu/doi/suppl/10.1126/science.aau1043/suppl_file/aau1043_datas3.gz
      """

rule decode_2019_hapmap:
   input: "aau1043_datas3.gz"
   output: "decode_2019_map.txt"
   shell:
      """
      python ../../tools/convert_bed_to_hapmap.py {input} > {output}
      """

recmaps = ["decode_2019_map.txt"]

## ----- Human Annotation Data
rule phastcons:
  output: "phastConsElements100way.txt.gz"
  shell:
    """
    curl http://hgdownload.soe.ucsc.edu/goldenPath/hg38/database/phastConsElements100way.txt.gz | \
     zcat | cut -f2- | grep -P '^chr[0-9]+\t' | gzip > {output}
    """

# ---- phastcons data ----
rule phastcons_bed:
  # VALIDATION: unclear from UCSC doc whether the .txt.gz is 0 or 1-indexed. 
  # Using table browser BED output produced a version that aligns with ours
  # NOTE: must be 100-way ELEMENT track
  input: "phastConsElements100way.txt.gz"
  output: "phastcons_100way.bed.gz"
  shell:
    """
     zcat {input} | bioawk -t '{{ print $1,$2,$3 }}' | sort --version-sort -k1,1 -k2,2n | bedtools merge | gzip > {output}
    """

# ---- gene tracks ----
rule ensembl_gff:
  output: "hg38.ensembl.gff3.gz"
  shell:
     """
     wget -O {output} http://ftp.ensembl.org/pub/release-107/gff3/homo_sapiens/Homo_sapiens.GRCh38.107.chr.gff3.gz 
     """

rule ensembl_gff_autos:
  input: "hg38.ensembl.gff3.gz"
  output: "hg38.ensembl_autos.bed.gz"
  shell:
     """
     zgrep -v '^#' {input} | sed s/^/chr/ | \
       grep -P '^chr[0-9]+\t' | bioawk -t '{{ print $1,$4-1,$5+1,$3 }}' | sort --version-sort -k1,1 -k2,2n | \
       sed 's/five_prime_UTR/5UTR/' | \
       sed 's/three_prime_UTR/3UTR/' | \
       gzip > {output}
     """

rule ncbi_refseq:
 output: "hg38.ncbiRefSeq.gtf.gz"
 shell: 
    """
    wget -O {output} https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/genes/hg38.ncbiRefSeq.gtf.gz
    """

rule ncbi_refseq_clean:
 # NOTE: we replace transcript with gene
 input: "hg38.ncbiRefSeq.gtf.gz"
 output: "hg38.refseq_autos.bed.gz"
 shell: 
    """
    zgrep -P '^chr[0-9]+\t' {input} | bioawk -t '{{ print $1,$4-1,$5+1,$3 }}' | \
     sed 's/transcript/gene/' | \
     sort --version-sort -k1,1 -k2,2n | gzip > {output}
    """

## ----- split out features
annotation_features = ['exon', '5UTR', '3UTR', 'CDS', 'gene'] 

rule split_feature_ensembl:
  input: ensembl="hg38.ensembl_autos.bed.gz"
  output: "hg38.{feature,[^_]+}_ensembl_autos.bed.gz"
  shell: 
     """
     zcat {input.ensembl} | bioawk -cbed ' $name ~ /^{wildcards.feature}$/ {{ print $chrom,$start,$end,$name }} ' | \
     sort --version-sort -k1,1 -k2,2n | bedtools merge | \
     gzip > {output}
     """

rule split_feature_refseq:
  input: refseq="hg38.refseq_autos.bed.gz"
  output: "hg38.{feature,[^_]+}_refseq_autos.bed.gz"
  shell: 
     """
     zcat {input.refseq} | bioawk -cbed ' $name ~ /^{wildcards.feature}$/ {{ print $chrom,$start,$end,$name }} ' | \
     sort --version-sort -k1,1 -k2,2n | bedtools merge | \
     gzip > {output}
     """

# merge the features from ensembl and refseq
rule merge_features:
  input: refseq="hg38.{feature,[^_]+}_refseq_autos.bed.gz", ensembl="hg38.{feature,[^_]+}_ensembl_autos.bed.gz"
  output: "hg38.{feature,[^_]+}_autos.bed.gz"
  shell: 
     """
     zcat {input.refseq} {input.ensembl} | \
      sort --version-sort -k1,1 -k2,2n | bedtools merge | \
      bioawk -t '{{ print $0,"{wildcards.feature}" }}' | \
      gzip > {output}
     """

rule phastcons_split:
  input: "phastcons_100way.bed.gz"
  output: "hg38.phastcons_autos.bed.gz"
  shell: 
     """
     zcat {input} | \
       sort --version-sort -k1,1 -k2,2n | bedtools merge | \
       bioawk -t '{{ print $0,"phastcons" }}' | \
       gzip > {output}
     """

rule merge_UTRs:
  input: "hg38.3UTR_autos.bed.gz", "hg38.5UTR_autos.bed.gz"
  output: "hg38.UTR_autos.bed.gz"
  shell: 
     """
     zcat {input[0]} {input[1]} | \
      sort --version-sort -k1,1 -k2,2n | bedtools merge | \
      bioawk -t '{{ print $0,"UTR" }}' | \
      gzip > {output}
     """
split = [f"hg38.{f}_autos.bed.gz" for f in annotation_features]
split += [f"hg38.{f}_refseq_autos.bed.gz" for f in annotation_features]
split += [f"hg38.{f}_ensembl_autos.bed.gz" for f in annotation_features]
split += ["hg38.phastcons_autos.bed.gz",  "hg38.UTR_autos.bed.gz"]

clean_annot = ["hg38.ensembl_autos.bed.gz", "hg38.refseq_autos.bed.gz"]
clean_annot += split

## ----- CADD annotation
#rule cadd:
#  # this version uses the B scores, so we don't use this
#  output: "cadd_whole_genome_SNVs.tsv.gz"
#  shell:
#    """
#    wget -O {output} https://krishna.gs.washington.edu/download/CADD/v1.6/GRCh38/whole_genome_SNVs.tsv.gz
#    """

rule cadd_sansB:
  output: "all_SNV.tsv.gz"
  shell:
    """
    wget -O {output} https://kircherlab.bihealth.org/download/CADD/bStatistic/GRCh38/all_SNV.tsv.gz
    """

rule cadd_bed:
  input: "all_SNV.tsv.gz"
  output: "cadd_whole_genome_SNVs.bed.gz"
  shell:
    """
     zcat {input[0]} | bioawk -t '{{print $1,$2,$2+1,$4,$6}}' | grep -v '^#' | \
       sed 's/^/chr/' | bedtools merge -i - -d -1 -c 1,5,5 -o count,mean,max | gzip > {output[0]}
    """

rule cadd_npz:
  input: cadd="cadd_whole_genome_SNVs.bed.gz", seqlens="hg38_seqlens.tsv"
  output: "cadd_whole_genome_SNVs.npz"
  run:
    seqlens = load_seqlens(input.seqlens)
    d = load_cadd_bed_scores(input.cadd, seqlens, mode='max')
    np.savez(output[0], **d)

rule cadd_cov_track:
  input: "cadd_whole_genome_SNVs.npz"
  output: "cadd_quantized.bed.gz"
  run:
    scores = np.load(input[0])

    quantile_bins = np.array([0, 0.3, 0.90, 0.94, 0.96, 0.98, 1])

    with open(output[0], 'w') as bed_file:
        for chrom in scores.keys():
            chrom_scores = scores[chrom]
            discretized_scores = pd.cut(chrom_scores, phred(quantiles), labels=False)
            prev_score = None
            prev_start = None
            for i in range(len(discretized_scores)):
                if prev_score != discretized_scores[i] or i == len(discretized_scores) - 1:
                    if prev_score is not None:
                        chrom_start = prev_start
                        chrom_end = i
                        score = prev_score
                        bed_line = f'{chrom}\t{chrom_start}\t{chrom_end}\t.\t{score}\n'
                        bed_file.write(bed_line)
                    prev_score = discretized_scores[i] if i < len(discretized_scores) - 1 else None
                    prev_start = i

rule cadd_cov_top:
  input: "cadd_whole_genome_SNVs.npz"
  output: "cadd_top{percent}_percent_unmerged.bed.gz"
  run:
    d = np.load(input[0])
    percent = float(wildcards.percent)
    thresh_score = phred(percent/100)
    print(f"percent={percent}, thresh_score={thresh_score}")
    quantize_track(d, thresh_score, label=f"CADD top {percent}%", bed_file=output[0], flip_inequality=False)

rule cadd_cov_bottom:
  input: "cadd_whole_genome_SNVs.npz"
  output: "cadd_bottom{percent}_percent_unmerged.bed.gz"
  run:
    d = np.load(input[0])
    percent = float(wildcards.percent)
    thresh_score = phred(1-percent/100)
    print(f"percent={percent}, thresh_score={thresh_score}")
    quantize_track(d, thresh_score, label=f"CADD bottom {percent}%", bed_file=output[0], flip_inequality=True)


rule cadd_merged:
  input: "cadd_{percent}percent_unmerged.bed.gz"
  output: "cadd_{percent}percent.bed.gz"
  shell:
    """
    zcat {input} | sort --version-sort -k1,1 -k2,2n | bedtools merge | gzip > {output}
    """

rule windows:
  input: seqlens="hg38_seqlens.tsv"
  output: "window_{width}.bed.gz"
  shell: 
     """
     bedtools makewindows -g {input.seqlens} -w {wildcards.width} > {output}
     """

rule cadd_simple_merged:
  input: "cadd_{percent}percent.bed.gz"
  output: "cadd_{percent}percent_merged{width}.bed.gz"
  shell:
    """
    bedtools merge -i {input} -d {wildcards.width} | gzip > {output}
    """

# take all CADD basepairs in a window and move them to the center, to 
# rough-grid tracks that have fewer contiguous 
rule cadd_simple:
  input: cadd="cadd_{percent}percent.bed.gz", windows="window_{width}.bed.gz"
  output: "cadd_{percent}percent_simple{width}.bed.gz"
  shell:
     """
     bedtools coverage -b {input.cadd} -a {input.windows} | \
     bioawk -t 'function ceil(x) {{return (x == int(x)) ? x : int(x)+1}} {{ if ($5 > 0) {{ print $1,($2+$3)/2 - int($5/2),($2+$3)/2 + ceil($5/2)}} }}' | \
       gzip > {output}
     """

cadd_annot = ["cadd_top6_percent.bed.gz", "cadd_top7_percent.bed.gz", "cadd_top8_percent.bed.gz"]
cadd_simple = ["cadd_top6_percent_simple100.bed.gz", "cadd_top6_percent_simple1000.bed.gz", "cadd_top6_percent_merged1.bed.gz",  
               "cadd_top6_percent_merged2.bed.gz"]
cadd_annot += cadd_simple
#cadd_annot += ["cadd_quantized.bed.gz"]

## ----- neutral track
# we remove all phastcons, exons, CDS, and UTRs
rule neutral_slop:
  input: exon="hg38.exons_autos.bed.gz", cds="hg38.CDS_autos.bed.gz", 
         UTR="hg38.UTR_autos.bed.gz", phastcons="hg38.phastcons_autos.bed.gz",
         seqlens="hg38_seqlens.tsv"
  output: "putatively_neutral__slop{slop}.bed.gz"
  shell:
     """
     zcat {input.exon} {input.cds} {input.UTR} {input.phastcons} | \
      bedtools slop -g {input.seqlens} -b {wildcards.slop}  | \
      sort --version-sort -k1,1 -k2,2n | bedtools merge | \
       bedtools complement -i - -g {input.seqlens} | gzip > {output}
     """

rule neutral:
  input: exon="hg38.exons_autos.bed.gz", cds="hg38.CDS_autos.bed.gz", 
         UTR="hg38.UTR_autos.bed.gz", phastcons="hg38.phastcons_autos.bed.gz",
         seqlens="hg38_seqlens.tsv"
  output: "putatively_neutral.bed.gz"
  shell:
     """
     zcat {input.exon} {input.cds} {input.UTR} {input.phastcons} | \
      sort --version-sort -k1,1 -k2,2n | bedtools merge | \
       bedtools complement -i - -g {input.seqlens} | gzip > {output}
     """


neutral = ["putatively_neutral.bed.gz",
           "putatively_neutral__slop200.bed.gz",
           "putatively_neutral__slop100.bed.gz",
           "cadd_bottom20_percent.bed.gz",
           "cadd_bottom30_percent.bed.gz",
           "cadd_bottom70_percent.bed.gz"
          ]


## ----- Accessible Regions
accessible = ["h1kg_strict.bed.gz", "no_centro_strict.bed"]

rule strict:
  output: "h1kg_strict.bed.gz"
  shell: 
    """
    curl http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/working/20160622_genome_mask_GRCh38/StrictMask/20160622.allChr.mask.bed | \
      gzip > {output}
    """

rule no_centro:
  input: centro="hg38_centro_slop.bed", seqlens="hg38_seqlens.tsv"
  output: "no_centro.bed"
  shell:
    """
    bedtools complement -i {input.centro} -g {input.seqlens} > {output}
    """

rule no_centro_strict:
  input: no_centro="no_centro.bed", seqlens="hg38_seqlens.tsv", strict="h1kg_strict.bed"
  output: "no_centro_strict.bed"
  shell:
    """
    bedtools intersect -a {input.no_centro} -b {input.strict} > {output}
    """


## ----- percent summaries
# calculate the percent of autosomal basepairs all the tracks cover
rule stats:
  input: clean_annot, cadd_annot, neutral
  output: "percent_coverage.tsv"
  shell: 
     """
     echo {input} | sort | xargs -n1 bash ../../tools/percent_genome.sh > {output} 
     """
     
stats = ["percent_coverage.tsv"]

rule all:
  input: clean_annot, recmaps, genome, neutral, cadd_annot, accessible #stats

