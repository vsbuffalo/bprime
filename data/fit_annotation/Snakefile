import gzip
import numpy as np
import pandas as pd
from bgspy.utils import load_seqlens, load_cadd_bed_scores
from bgspy.utils import quantize_track, phred, summarize_npz_by_bin

AUTOS = list(range(1, 23))
AUTOSEX = AUTOS + ['X', 'Y']

## ------ Human genome data

genome = ["hg38.fa.gz", "hg38_seqlens.tsv"]

rule hg38:
  # fixes chromosome labels to start with 'chr'
  output: "hg38.fa.gz"
  shell:
    """
    curl http://ftp.ensembl.org/pub/release-107/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz | \
      zcat | sed 's/^>/>chr/' | gzip > {output}
    """

## only keep autosomes
rule seqlens:
  input: "hg38.fa.gz"
  output: "hg38_seqlens.tsv"
  shell:
    """
      bioawk -cfastx '{{ print $name,length($seq) }}' hg38.fa.gz | \
      grep -P '^chr[0-9X]+' |  \
      sort  --version-sort -k 1,1 -k2,2n > {output}
    """

## ----- Human Recombination Maps
rule decode_2019_map:
   output: "aau1043_datas3.gz"
   shell:
      """
      wget -O {output} https://www.science.org/doi/suppl/10.1126/science.aau1043/suppl_file/aau1043_datas3.gz
      #wget -O {output} https://www-science-org.libproxy.berkeley.edu/doi/suppl/10.1126/science.aau1043/suppl_file/aau1043_datas3.gz
      """

rule decode_2019_hapmap:
   input: "aau1043_datas3.gz"
   output: "decode_2019_map.txt"
   shell:
      """
      python ../../tools/convert_bed_to_hapmap.py {input} > {output}
      """

recmaps = ["decode_2019_map.txt"]

## ----- Human Annotation Data
rule phastcons:
  output: "phastConsElements100way.txt.gz"
  shell:
    """
    curl http://hgdownload.soe.ucsc.edu/goldenPath/hg38/database/phastConsElements100way.txt.gz | \
     zcat | cut -f2- | grep -P '^chr[0-9]+\t' | gzip > {output}
    """

# ---- phastcons data ----
rule phastcons_bed:
  # VALIDATION: unclear from UCSC doc whether the .txt.gz is 0 or 1-indexed. 
  # Using table browser BED output produced a version that aligns with ours
  # NOTE: must be 100-way ELEMENT track
  input: "phastConsElements100way.txt.gz"
  output: "phastcons_100way.bed.gz"
  shell:
    """
     zcat {input} | bioawk -t '{{ print $1,$2,$3 }}' | sort --version-sort -k1,1 -k2,2n | bedtools merge | gzip > {output}
    """

# ---- gene tracks ----
rule ensembl_gff:
  output: "hg38.ensembl.gff3.gz"
  shell:
     """
     wget -O {output} http://ftp.ensembl.org/pub/release-107/gff3/homo_sapiens/Homo_sapiens.GRCh38.107.chr.gff3.gz 
     """

rule ensembl_gff_autos:
  input: "hg38.ensembl.gff3.gz"
  output: "hg38.ensembl_autos.bed.gz"
  shell:
     """
     zgrep -v '^#' {input} | sed s/^/chr/ | \
       grep -P '^chr[0-9]+\t' | bioawk -t '{{ print $1,$4-1,$5+1,$3 }}' | sort --version-sort -k1,1 -k2,2n | \
       sed 's/five_prime_UTR/5UTR/' | \
       sed 's/three_prime_UTR/3UTR/' | \
       gzip > {output}
     """

rule ncbi_refseq:
 output: "hg38.ncbiRefSeq.gtf.gz"
 shell: 
    """
    wget -O {output} https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/genes/hg38.ncbiRefSeq.gtf.gz
    """

rule ncbi_refseq_clean:
 # NOTE: we replace transcript with gene
 input: "hg38.ncbiRefSeq.gtf.gz"
 output: "hg38.refseq_autos.bed.gz"
 shell: 
    """
    zgrep -P '^chr[0-9]+\t' {input} | bioawk -t '{{ print $1,$4-1,$5+1,$3 }}' | \
     sed 's/transcript/gene/' | \
     sort --version-sort -k1,1 -k2,2n | gzip > {output}
    """

## ----- split out features
annotation_features = ['exon', '5UTR', '3UTR', 'CDS', 'gene'] 

rule split_feature_ensembl:
  input: ensembl="hg38.ensembl_autos.bed.gz"
  output: "hg38.{feature,[^_]+}_ensembl_autos.bed.gz"
  shell: 
     """
     zcat {input.ensembl} | bioawk -cbed ' $name ~ /^{wildcards.feature}$/ {{ print $chrom,$start,$end,$name }} ' | \
     sort --version-sort -k1,1 -k2,2n | bedtools merge | \
     gzip > {output}
     """

rule split_feature_refseq:
  input: refseq="hg38.refseq_autos.bed.gz"
  output: "hg38.{feature,[^_]+}_refseq_autos.bed.gz"
  shell: 
     """
     zcat {input.refseq} | bioawk -cbed ' $name ~ /^{wildcards.feature}$/ {{ print $chrom,$start,$end,$name }} ' | \
     sort --version-sort -k1,1 -k2,2n | bedtools merge | \
     gzip > {output}
     """

# merge the features from ensembl and refseq
rule merge_features:
  input: refseq="hg38.{feature,[^_]+}_refseq_autos.bed.gz", ensembl="hg38.{feature,[^_]+}_ensembl_autos.bed.gz"
  output: "hg38.{feature,[^_]+}_autos.bed.gz"
  shell: 
     """
     zcat {input.refseq} {input.ensembl} | \
      sort --version-sort -k1,1 -k2,2n | bedtools merge | \
      bioawk -t '{{ print $0,"{wildcards.feature}" }}' | \
      gzip > {output}
     """

rule phastcons_split:
  input: "phastcons_100way.bed.gz"
  output: "hg38.phastcons_autos.bed.gz"
  shell: 
     """
     zcat {input} | \
       sort --version-sort -k1,1 -k2,2n | bedtools merge | \
       bioawk -t '{{ print $0,"phastcons" }}' | \
       gzip > {output}
     """

rule merge_UTRs:
  input: "hg38.3UTR_autos.bed.gz", "hg38.5UTR_autos.bed.gz"
  output: "hg38.UTR_autos.bed.gz"
  shell: 
     """
     zcat {input[0]} {input[1]} | \
      sort --version-sort -k1,1 -k2,2n | bedtools merge | \
      bioawk -t '{{ print $0,"UTR" }}' | \
      gzip > {output}
     """
split = [f"hg38.{f}_autos.bed.gz" for f in annotation_features]
split += [f"hg38.{f}_refseq_autos.bed.gz" for f in annotation_features]
split += [f"hg38.{f}_ensembl_autos.bed.gz" for f in annotation_features]
split += ["hg38.phastcons_autos.bed.gz",  "hg38.UTR_autos.bed.gz"]

clean_annot = ["hg38.ensembl_autos.bed.gz", "hg38.refseq_autos.bed.gz"]
clean_annot += split

## ----- CADD annotation
#rule cadd:
#  # this version uses the B scores, so we don't use this
#  output: "cadd_whole_genome_SNVs.tsv.gz"
#  shell:
#    """
#    wget -O {output} https://krishna.gs.washington.edu/download/CADD/v1.6/GRCh38/whole_genome_SNVs.tsv.gz
#    """

rule cadd_sansB:
  output: "all_SNV.tsv.gz"
  shell:
    """
    wget -O {output} https://kircherlab.bihealth.org/download/CADD/bStatistic/GRCh38/all_SNV.tsv.gz
    """

rule cadd_bed:
  input: "all_SNV.tsv.gz"
  output: "cadd_whole_genome_SNVs.bed.gz"
  shell:
    """
     zcat {input[0]} | bioawk -t '{{print $1,$2,$2+1,$4,$6}}' | grep -v '^#' | \
       sed 's/^/chr/' | bedtools merge -i - -d -1 -c 1,5,5 -o count,mean,max | gzip > {output[0]}
    """

rule cadd_npz:
  input: cadd="cadd_whole_genome_SNVs.bed.gz", seqlens="hg38_seqlens.tsv"
  output: "cadd_whole_genome_SNVs.npz"
  run:
    seqlens = load_seqlens(input.seqlens)
    d = load_cadd_bed_scores(input.cadd, seqlens, mode='max')
    np.savez(output[0], **d)

# note: I call these quantiles but this a bit inaccurate -- 
QUANTS = [0, 0.8, 0.9, 0.92, 0.94, 0.96, 0.98, 0.99, 1]
rule cadd_cov_track:
  input: "cadd_whole_genome_SNVs.npz"
  output: "unmerged_cadd_quantized_{width}bp_{fun}.bed.gz"
  run:
    # the phred-scale is logged hence the 0.9999...
    quantiles = np.array(QUANTS)
    labs = np.copy(quantiles)
    labs[-1] = 1
    quantiles[quantiles == 1] = 1 - 1e-9
    score_quantiles = phred(quantiles)
    width = int(wildcards.width)
    fun = {'max': np.nanmax, 'mean': np.nanmean}[wildcards.fun]
    res, ranges = summarize_npz_by_bin(input[0], width, fun)
    openfile = gzip.open(output[0], 'wt')
    for chrom, scores in res.items():
      bins = labs[np.digitize(scores, score_quantiles)]
      for i, val in enumerate(bins):
        start, end = ranges[chrom][i, :]
        if val == val - 1e9:
            val = 1
        openfile.write(f"{chrom}\t{start}\t{end}\t{val}\n")

rule cadd_cov_track_merged:
  input: "unmerged_cadd_quantized_{width}bp_{fun}.bed.gz"
  output: "cadd_quantile{quantile}_{width}bp_{fun}.bed.gz"
  shell:
    """
    zcat {input} | bioawk -t '{{ if ($4 == {wildcards.quantile} ) {{ print $0 }} }}'  | \
        bedtools merge | \
        bioawk -t -v "q={wildcards.quantile}" '{{ print $0,"quantile_"q }}' | \
        gzip > {output}
    """
 
rule cadd_cov_top:
  input: "cadd_whole_genome_SNVs.npz"
  output: "cadd_top{percent}_percent_unmerged.bed.gz"
  run:
    d = np.load(input[0])
    percent = float(wildcards.percent)
    thresh_score = phred(percent/100)
    print(f"percent={percent}, thresh_score={thresh_score}")
    quantize_track(d, thresh_score, label=f"CADD top {percent}%", bed_file=output[0], flip_inequality=False)

rule cadd_cov_bottom:
  input: "cadd_whole_genome_SNVs.npz"
  output: "cadd_bottom{percent}_percent_unmerged.bed.gz"
  run:
    d = np.load(input[0])
    percent = float(wildcards.percent)
    thresh_score = phred(1-percent/100)
    print(f"percent={percent}, thresh_score={thresh_score}")
    quantize_track(d, thresh_score, label=f"CADD bottom {percent}%", bed_file=output[0], flip_inequality=True)


rule cadd_merged:
  input: "cadd_{percent}percent_unmerged.bed.gz"
  output: "cadd_{percent}percent.bed.gz"
  shell:
    """
    zcat {input} | sort --version-sort -k1,1 -k2,2n | bedtools merge | gzip > {output}
    """

rule windows:
  input: seqlens="hg38_seqlens.tsv"
  output: "window_{width}.bed.gz"
  shell: 
     """
     bedtools makewindows -g {input.seqlens} -w {wildcards.width} > {output}
     """

rule cadd_simple_merged:
  input: "cadd_{percent}percent.bed.gz"
  output: "cadd_{percent}percent_merged{width}.bed.gz"
  shell:
    """
    bedtools merge -i {input} -d {wildcards.width} | gzip > {output}
    """

# take all CADD basepairs in a window and move them to the center, to 
# rough-grid tracks that have fewer contiguous 
rule cadd_simple:
  input: cadd="cadd_{percent}percent.bed.gz", windows="window_{width}.bed.gz"
  output: "cadd_{percent}percent_simple{width}.bed.gz"
  shell:
     """
     bedtools coverage -b {input.cadd} -a {input.windows} | \
     bioawk -t 'function ceil(x) {{return (x == int(x)) ? x : int(x)+1}} {{ if ($5 > 0) {{ print $1,($2+$3)/2 - int($5/2),($2+$3)/2 + ceil($5/2)}} }}' | \
       gzip > {output}
     """

cadd_annot = ["cadd_top6_percent.bed.gz", "cadd_top7_percent.bed.gz", "cadd_top8_percent.bed.gz", "cadd_top10_percent.bed.gz"]
cadd_simple = ["cadd_top6_percent_simple100.bed.gz", "cadd_top6_percent_simple1000.bed.gz", "cadd_top6_percent_merged1.bed.gz",  
               "cadd_top6_percent_merged2.bed.gz"]
cadd_annot += cadd_simple
cadd_annot += [f"cadd_quantile{q}_5bp_mean.bed.gz" for q in QUANTS]

## ----- neutral track
# we remove all phastcons, exons, CDS, and UTRs
rule neutral_slop:
  input: exon="hg38.exons_autos.bed.gz", cds="hg38.CDS_autos.bed.gz", 
         UTR="hg38.UTR_autos.bed.gz", phastcons="hg38.phastcons_autos.bed.gz",
         seqlens="hg38_seqlens.tsv"
  output: "putatively_neutral__slop{slop}.bed.gz"
  shell:
     """
     zcat {input.exon} {input.cds} {input.UTR} {input.phastcons} | \
      bedtools slop -g {input.seqlens} -b {wildcards.slop}  | \
      sort --version-sort -k1,1 -k2,2n | bedtools merge | \
       bedtools complement -i - -g {input.seqlens} | gzip > {output}
     """

rule neutral:
  input: exon="hg38.exons_autos.bed.gz", cds="hg38.CDS_autos.bed.gz", 
         UTR="hg38.UTR_autos.bed.gz", phastcons="hg38.phastcons_autos.bed.gz",
         seqlens="hg38_seqlens.tsv"
  output: "putatively_neutral.bed.gz"
  shell:
     """
     zcat {input.exon} {input.cds} {input.UTR} {input.phastcons} | \
      sort --version-sort -k1,1 -k2,2n | bedtools merge | \
       bedtools complement -i - -g {input.seqlens} | gzip > {output}
     """


neutral = ["putatively_neutral.bed.gz",
           "putatively_neutral__slop200.bed.gz",
           "putatively_neutral__slop100.bed.gz",
           "cadd_bottom20_percent.bed.gz",
           "cadd_bottom30_percent.bed.gz",
           "cadd_bottom70_percent.bed.gz"
          ]


## ----- Accessible Regions
accessible = ["h1kg_strict.bed.gz", "no_centro_strict.bed"]

rule strict:
  output: "h1kg_strict.bed.gz"
  shell: 
    """
    curl http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/working/20160622_genome_mask_GRCh38/StrictMask/20160622.allChr.mask.bed | \
      gzip > {output}
    """

rule centro:
  output: "hg38_centro.bed"
  shell:
    """
    curl http://hgdownload.cse.ucsc.edu/goldenPath/hg38/database/cytoBand.txt.gz | zgrep "acen" | \
     grep -v "chrY" | grep -v "chrX" | sort --version-sort -k1,1 -k2,2n > {output}
    """

rule centro_slop:
  output: "hg38_centro_slop.bed"
  input: centro="hg38_centro.bed", seqlens="hg38_seqlens.tsv"
  shell:
    """
    bedtools slop -g {input.seqlens} -b 5000000 -i {input.centro} | sort --version-sort -k1,1 -k2,2n > {output}
    """
 
rule no_centro:
  input: centro="hg38_centro_slop.bed", seqlens="hg38_seqlens.tsv"
  output: "no_centro.bed"
  shell:
    """
    bedtools complement -i {input.centro} -g {input.seqlens} > {output}
    """

rule no_centro_strict:
  input: no_centro="no_centro.bed", seqlens="hg38_seqlens.tsv", strict="h1kg_strict.bed.gz"
  output: "no_centro_strict.bed"
  shell:
    """
    bedtools intersect -a {input.no_centro} -b {input.strict} > {output}
    """


## ----- percent summaries
# calculate the percent of autosomal basepairs all the tracks cover
rule stats:
  input: clean_annot, cadd_annot, neutral
  output: "percent_coverage.tsv"
  shell: 
     """
     echo {input} | sort | xargs -n1 bash ../../tools/percent_genome.sh > {output} 
     """
     
stats = ["percent_coverage.tsv"]

rule all:
  input: clean_annot, recmaps, genome, neutral, cadd_annot, accessible #stats

