import os
import pickle
import re
import pandas as pd
from bgspy.utils import read_phylofit, get_human_branch_length, readfq, readfile
from bgspy.models import BGSModel

PF_DIR = 'phylofit_estimates/'
# MODEL_FILE = '../bmaps/bgspy/bmap_hg38_6x7grid_10000step_10000N_cds_utrs_phastcons_full.pkl'
MODEL_FILE = '../bmaps/bgspy/bmap_hg38_6x7grid_10000step_10000N_cds_utrs_phastcons.pkl'
RESCALE_MODEL_FILE = '../bmaps/bgspy/bmap_rescaled_hg38_6x7grid_10000step_10000N_cds_utrs_phastcons.pkl'
FIT_FILE = '../../fits/hg38_cds_utrs_phastcons_simplex/hg38_cds_utrs_phastcons/window_1000000/mle.pkl'

rule get_knowncanonical_multiz:
  output: "knownCanonical.exonNuc.fa.gz"
  shell:
     """
     wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/multiz20way/alignments/knownCanonical.exonNuc.fa.gz
     """

rule separate_alns:
   # note the "ensembl_ucsc_stable_id.tsv" file was downloaded from biomart website
   input: multiz="knownCanonical.exonNuc.fa.gz", map="ensembl_ucsc_stable_id.tsv"
   output: "cds_alns/dummy.txt"
   shell:
       """
       python ../../tools/split_multiz.py {input.multiz} cds_alns/ {input.map} 
       touch cds_alns/dummy.txt
       """
    

rule windows:
  input: annot="../annotation/hg38_seqlens.tsv"
  output: "hg38_windows_{width}.bed"
  shell:
    """
    bedtools makewindows -g {input.annot} -w {wildcards.width} | bedtools sort > {output[0]}
    """

rule ratchet_data:
  # this is the full phastcons raw segment ratchet data, calculated alongside 
  # the B scores.
  input: model = MODEL_FILE, fit = FIT_FILE
  output: "ratchet_data.bed"
  shell: 
     """
     bgspy subrate --bs-file {input.model} --fit {input.fit} --outfile {output[0]}
     """

rule ratchet_rescale_data_split:
  input: model = RESCALE_MODEL_FILE, fit = FIT_FILE
  output: "ratchet_rescaled_data_cds.bed", "ratchet_rescaled_data_utr.bed", "ratchet_rescaled_data_phastcons.bed"
  shell: 
     """
     bgspy subrate --split --bs-file {input.model} --fit {input.fit} --outfile "ratchet_rescaled_data"
     """

rule ratchet_rescale_data:
  input: model = RESCALE_MODEL_FILE, fit = FIT_FILE
  output: "ratchet_rescaled_data.bed"
  shell: 
     """
     bgspy subrate --bs-file {input.model} --fit {input.fit} --outfile {output[0]}
     """

rule ratchet_data_cds:
  input: model = MODEL_FILE, fit = FIT_FILE
  output: "ratchet_data_cds.bed", "ratchet_data_utr.bed", "ratchet_data_phastcons.bed"
  shell: 
     """
     bgspy subrate --split --bs-file {input.model} --fit {input.fit} --outfile "ratchet_data"
     """

rule uricchio_data:
  input: data="41559_2019_890_MOESM3_ESM.txt", cds_stats="../annotation/ensembl_cds_canonical_protein_coding_stats.tsv"
  output: "uricchio_data.tsv"
  run: 
    cols = ('gene_id', 'n_nonsyn', 'nonsyn_daf', 'n_syn', 
        'syn_daf', 'fixed_nonsyn', 'fixed_syn')

    gr = pd.read_csv(input.data,
                     sep='\t', names=cols, comment='#')
    gr['dnDs'] = gr['fixed_nonsyn'] / gr['fixed_syn']

    cd = pd.read_csv(input.cds_stats, sep='\t')

    gr = gr.merge(cd, on='gene_id')
    gr['total_fixed'] = gr['fixed_nonsyn']+gr['fixed_syn']
    gr['syn_prop'] = gr['fixed_syn'] / gr['S']
    gr['nonsyn_prop'] = gr['fixed_nonsyn'] / gr['N']
    gr['total_prop'] = gr['total_fixed'] / (gr['S'] + gr['N'])
    gr['dNdS'] = gr['fixed_nonsyn']/gr['fixed_syn']
    gr = gr[~gr['chrom'].isin(['chrX', None])]


    new_cols = ['chrom',  'start', 'end', 'gene_id', 'n_nonsyn', 'n_syn',
                'fixed_nonsyn', 'fixed_syn', 'dnDs', 
                'total_fixed', 'len', 'cai', 'gc', 'gc3', 'syn_prop', 
                'nonsyn_prop', 'total_prop', 'dNdS', 'S', 'N']

    gr = gr.sort_values(['chrom', 'start', 'end'])
    gr = gr[new_cols]
    gr = gr.rename(columns={'chrom': '#chrom'})
    gr.to_csv(output[0], sep='\t', index=False)

rule uricchio_merged:
  """
  Merge in the raw ratchet data and the phylofit substitution rates for
  the whole CDS from ensembl_cds_canonical_protein_coding_stats.tsv.
  """
  input: data="uricchio_data.tsv", ratchet="ratchet_rescaled_data_cds.bed", 
         pf="phylofit_rates.bed", rescaled_ratchet="ratchet_rescaled_data.bed"
  output: "uricchio_data_merged.bed"
  shell:
      """
      bedtools map -a {input.data} -b {input.ratchet} -c 6,7 -o mean,sum > tmp.bed
      bedtools map -a tmp.bed -b {input.rescaled_ratchet} -c 6,7 -o mean,sum > tmp2.bed
      bedtools map -a tmp2.bed -b {input.pf} -c 4,5 -o mean,sum > {output[0]}
      rm -f tmp.bed tmp2.bed
      """

rule ratchet_windows:
  input: ratchet="ratchet_data.bed", win="hg38_windows_{width}.bed"
  output: "ratchet_rates_binned_{width}"
  shell:
    """
    bedtools map -a {input.win} -b {input.ratchet} -c 5,6,7 -o mean,mean,sum > {output}
    """

rule ratchet_recale_windows:
  input: ratchet="ratchet_rescaled_data.bed", win="hg38_windows_{width}.bed"
  output: "ratchet_rescaled_rates_binned_{width}"
  shell:
    """
    bedtools map -a {input.win} -b {input.ratchet} -c 5,6,7 -o mean,mean,sum > {output}
    """


window_ratchet = ["ratchet_rates_binned_1000000.bed", 
                  "ratchet_rates_binned_100000.bed",
                  "ratchet_rates_binned_5000000.bed"]

rescale_window_ratchet = ["ratchet_rescaled_rates_binned_1000000.bed", 
                          "ratchet_rescaled_rates_binned_100000.bed",
                          "ratchet_rescaled_rates_binned_5000000.bed"]


ALL_FILES = [
             "cds_alns/dummy.txt",
             "ratchet_data.bed", 
             "uricchio_data.tsv", *window_ratchet,  
             "uricchio_data_merged.bed",  "ratchet_data_cds.bed", 
             "ratchet_rescaled_data.bed", 
             *rescale_window_ratchet,
             "ratchet_data_utr.bed", "ratchet_data_phastcons.bed"]

rule all:
  input: ALL_FILES

