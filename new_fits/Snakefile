"""
Modified Snakemake-based model fitting pipeline


Directory structure:

 main/
   fits/windowsize/mutation/
     CDS_gene_phastcons/
     CDS_gene/
     CDS_phastcons/
     gene_phastcons/

"""
import sys
from os.path import join
import numpy as np
from bgspy.utils import load_seqlens, load_pickle

if '--configfile' in sys.argv:
    i = sys.argv.index('--configfile')
elif '--configfiles' in sys.argv:
    i = sys.argv.index('--configfiles')
config_path = sys.argv[i+1]

# ---- load config file
# NOTE: name should match this current directory!

name = config["name"]
settings = config["settings"]
files = config["files"]
features = config["features"]
params = config["params"]
fits = config["fits"]
data = config["data"]

# set up the data
data_path = data['path']
pops = data['pops']
chroms = load_seqlens(files['seqlens'], 
                      exclude=['chrM', 'chrX', 'chrY'])
chrom_list = list(chroms.keys())

do_rescale = any([f['rescaled'] for f in fits])


# do we need to split the B' map processing?
splits = settings.get('chrom_splits', None)
if splits is not None:
    chrom_chunks = [chrom_list[i:i + splits] for i in range(0, len(chrom_list), splits)]
    print(f"B' are created in chunks, {chrom_chunks}")


# globals
N = params['N']
#njack = settings['num_jackknife_samples']

# ------- build the output files
# NOTE: the B/B' maps can be reused across runs which 
# vary in data. The .. is because fits are run in subdirs
# NOTE: the 'name' is the ID here, and should be the name of the feature set

# B and B' map params
step = params['step']

if 'grid' in params:
    grid_str = params['grid']
    Bs_file = f"bmaps/bmap_{grid_str}grid_{step}step_{N}N__{name}_{{tracktype}}.pkl"

    # Note: the locally-rescaled B/B' maps are **fit specific**
    # so in the fit subdirectory
    Bs_file_rescaled = f"fits/pop_{{popl}}/window_{{window}}/type_{{tracktype}}/mutrate_{{mutrate}}/rescaled/rescaled_bmap_{name}_bmap_B_{grid_str}grid_{step}step_{N}N__{name}_{{tracktype}}.pkl"
else:
    # we do separate w and t grids, and rename the B maps accordingly]
    wgrid = params['wgrid']
    tgrid = params['tgrid']
    Bs_file = f"bmaps/bmap_{wgrid}w{tgrid}t_{step}step_{N}N__{name}_{{tracktype}}.pkl"

    # Note: the locally-rescaled B/B' maps are **fit specific**
    # so in the fit subdirectory
    Bs_file_rescaled = f"fits/pop_{{popl}}/window_{{window}}/type_{{tracktype}}/mutrate_{{mutrate}}/rescaled/rescaled_bmap_{name}_bmap_B_{wgrid}w{tgrid}t_{step}step_{N}N__{name}_{{tracktype}}.pkl"

   
Bs_files = [Bs_file]
if do_rescale:
    Bs_files.append(Bs_file_rescaled)

## main fit data
# the data that goes into the likelihood model

model_data = []
mle_fits = []
loo_fits = []
jackknife_fits = []
preds = []
for popl in pops:
    for fit_specs in fits:
        # get some specs out
        window = fit_specs['window']
        mutrate = fit_specs['mu']
        rescale = fit_specs['rescaled']
        do_loo = fit_specs['loo']
        do_predict = fit_specs['predict']
        do_predict_mu = fit_specs.get('predict_mu', False)
        predict_jk = fit_specs.get('predict_jk', False)
        jackknife_windows = fit_specs['jackknife']
        tracktype = fit_specs['type']

        # model data -- shared for all fits 
        path = join("fits", f"pop_{popl}", f"window_{window}", f"type_{tracktype}")
        data = join(path, f'model_data.pkl')
        model_data.append(data)

        # these are fit-specific
        # main MLE fitting
        fit_path = join(path, f"mutrate_{mutrate}")

        # we may have to do uncertainty for both original and rescaled
        # so, we for this for the main fit directory, and rescaled/
        fit_dirs = ["initial"]
        if rescale:
            fit_dirs.append("rescaled")

        for fit_dir in fit_dirs:
            this_fit_path = join(fit_path, fit_dir)

            # the initial or rescaled mle fit
            mle = join(this_fit_path, f"mle.pkl")
            mle_fits.append(mle)
 
            # leave-one-out chromosome fits
            if do_loo:
                for chrom in chroms:
                    loo_fits.append(join(this_fit_path, "loo_chrom", f"loo_{chrom}.pkl"))

            if do_predict:
                preds.append(join(this_fit_path, "predicted_subrates.tsv"))

            if do_predict_mu:
                preds.append(join(this_fit_path, f"predicted_subrates_{do_predict_mu}.tsv"))

            # block-jackknives
            if jackknife_windows:
                if fit_dir == 'rescaled' and not fit_specs.get('jackknife_rescaled', False):
                    continue
                if isinstance(jackknife_windows, int):
                    jackknife_windows = [jackknife_windows]
                else:
                    assert(isinstance(jackknife_windows, list))
                for (jk_window, njack) in jackknife_windows:
                    jk_dir = join(this_fit_path, "jackknife", f"block_{jk_window}")
                    for frac in np.linspace(0, 1, njack+1)[:-1]:
                        jackknife_fits.append(join(jk_dir, f"jackknife_{frac}.pkl"))
                        if do_predict_mu and predict_jk:
                            jackknife_fits.append(join(jk_dir, "predicted_subrates", f"jackknife_{frac}__{do_predict_mu}.tsv"))


# for debuggin
#print(model_data)
#print(mle_fits)
#print(loo_fits)
#print(jackknife_fits)
#sys.exit()

# ------- rules

# ---- build the annotation tracks
rule annotation_full:
  input: config_path=config_path, seqlens=files['seqlens']
  output: f"tracks/{name}_full.bed.gz"
  resources:
    mem_mb=120000,
    time_min=120 
  shell:
     """
     bgspy tracks {input.config_path} --full --seqlens {input.seqlens} | gzip > {output}
     """

rule annotation:
  input: config_path=config_path, seqlens=files['seqlens']
  output: f"tracks/{name}_sparse.bed.gz"
  resources:
    mem_mb=120000,
    time_min=120 
  shell:
     """
     bgspy tracks {input.config_path} --seqlens {input.seqlens} | gzip > {output}
     """

# ---- build both bmaps
rule bmap_b:
  input: seqlens=files['seqlens'],
         recmap=files['recmap'],
         features="tracks/{name}_{tracktype}.bed.gz"
  output: pkl_b_file="bmaps/bmap_B_{grid_str,[0-9x]+}grid_{step}step_{N}N__{name}_{tracktype}.pkl"
  benchmark: "benchmarks/bmap_{grid_str,[0-9x]+}grid_{step}step_{N}N__{name}_{tracktype}.txt"
  resources:
    mem_mb=300000,
    time_min=4320,
    threads=40
  shell:
    """
    bgspy calcb \
      --recmap {input.recmap} --annot {input.features} \
      --seqlens {input.seqlens} --g '{wildcards.grid_str}' \
      --output {output} --popsize {wildcards.N} \
      --ncores {resources.threads} --only-B \
      --step {wildcards.step}
    """

if splits is None:
  rule bmap_bp:
    input: seqlens=files['seqlens'],
           recmap=files['recmap'],
           features="tracks/{name}_{tracktype}.bed.gz"
    output: pkl_b_file="bmaps/bmap_Bp_{grid_str,[0-9x]+}grid_{step}step_{N}N__{name}_{tracktype}.pkl"
    benchmark: "benchmarks/bmap_{grid_str,[0-9x]+}grid_{step}step_{N}N__{name}_{tracktype}.txt"
    resources:
      mem_mb=500000,
      time_min=4320,
      threads=40
    shell:
      """
      bgspy calcb \
        --recmap {input.recmap} --annot {input.features} \
        --seqlens {input.seqlens} --g '{wildcards.grid_str}' \
        --output {output} --popsize {wildcards.N} \
        --ncores-Bp {resources.threads} --only-Bp \
        --step {wildcards.step}
      """

  rule bmap_rescale:
    input: seqlens=files['seqlens'],
           recmap=files['recmap'],
           features=f"tracks/{name}_{{tracktype}}.bed.gz",
           fit="fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/initial/mle.pkl",
           b=Bs_file
    output: pkl_b_file="fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/rescaled/rescaled_bmap_{name}_bmap_B_{grid_str}grid_{step}step_{N}N__{name}_{tracktype}.pkl"
    resources:
      mem_mb=200000,
      time_min=4320,
      threads=30
    shell:
      """
      bgspy calcb \
        --recmap {input.recmap} --annot {input.features} \
        --seqlens {input.seqlens} --g '{wildcards.grid_str}' \
        --output {output} --popsize {wildcards.N} \
        --ncores {resources.threads} --ncores-Bp {resources.threads} \
        --step {wildcards.step} \
        --rescale-fit {input.fit} --only-Bp \
        --rescale-Bp-file {input.b}
      """

else:
  split_strs = ['_'.join(chrs) for chrs in chrom_chunks]
  all_bmaps = [f"bmaps/{chrs}/bmap_Bp_{{grid_str,[0-9x]+}}grid_{{step}}step_{{N}}N__{{name}}_{{tracktype}}.pkl" for chrs in split_strs]
  print(all_bmaps)
  rule bmap_bp_combine:
    input: all_bmaps
    output: pkl_b_file="bmaps/bmap_Bp_{grid_str,[0-9x]+}grid_{step}step_{N}N__{name}_{tracktype}.pkl"
    resources:
      mem_mb=800000,
      time_min=4320,
    shell:
      """
      bgspy merge --output {output} {input}
      """

  fmt = "fits/pop_{{popl}}/window_{{window}}/type_{{tracktype}}/mutrate_{{mutrate}}/rescaled/{chrs}/rescaled_bmap_{{name}}_bmap_B_{{grid_str}}grid_{{step}}step_{{N}}N__{{name}}_{{tracktype}}.pkl"
  all_bmaps_rescaled = [fmt.format(chrs=chrs) for chrs in split_strs]
  rule bmap_bp_rescale_combine:
    input: all_bmaps_rescaled
    output: pkl_b_file="fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/rescaled/rescaled_bmap_{name}_bmap_B_{grid_str}grid_{step}step_{N}N__{name}_{tracktype}.pkl"
    resources:
      mem_mb=800000,
      time_min=4320,
    shell:
      """
      bgspy merge --output {output} {input}
      """

rule bmap_bp_rescale_split:
  input: seqlens=files['seqlens'],
         recmap=files['recmap'],
         features="tracks/{name}_{tracktype}.bed.gz",
         fit="fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/initial/mle.pkl",
         b=Bs_file
  output: pkl_b_file="fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/rescaled/{chrom_split}/rescaled_bmap_{name}_bmap_B_{grid_str}grid_{step}step_{N}N__{name}_{tracktype}.pkl"
  resources:
    mem_mb=500000,
    time_min=4320,
    threads=30
  shell:
    """
    chroms="{wildcards.chrom_split}"
    chroms=${{chroms//_/' '}}

    # build the --chrom args
    chrom_args=""
    for chrom in $chroms; do
        chrom_args+=" --chrom $chrom"
    done

    bgspy calcb \
      --recmap {input.recmap} --annot {input.features} \
      --seqlens {input.seqlens} --g '{wildcards.grid_str}' \
      --output {output} --popsize {wildcards.N} \
      --ncores {resources.threads} --ncores-Bp {resources.threads} \
      --step {wildcards.step} \
      $chrom_args \
      --rescale-fit {input.fit} --only-Bp \
      --rescale-Bp-file {input.b}
    """


rule bmap_bp_split:
  input: seqlens=files['seqlens'],
         recmap=files['recmap'],
         features="tracks/{name}_{tracktype}.bed.gz"
  output: pkl_b_file="bmaps/{chrom_split}/bmap_Bp_{grid_str,[0-9x]+}grid_{step}step_{N}N__{name}_{tracktype}.pkl"
  resources:
    mem_mb=800000,
    time_min=4320,
    threads=20
  shell:
    """
    chroms="{wildcards.chrom_split}"
    chroms=${{chroms//_/' '}}

    # build the --chrom args
    chrom_args=""
    for chrom in $chroms; do
        chrom_args+=" --chrom $chrom"
    done

    bgspy calcb \
      --recmap {input.recmap} --annot {input.features} \
      --seqlens {input.seqlens} --g '{wildcards.grid_str}' \
      --output {output} --popsize {wildcards.N} \
      $chrom_args \
      --ncores-Bp {resources.threads} --only-Bp \
      --step {wildcards.step}
    """

rule combine_bmaps:
  input: b="bmaps/bmap_B_{grid_str,[0-9x]+}grid_{step}step_{N}N__{name}_{tracktype}.pkl", 
         bp="bmaps/bmap_Bp_{grid_str,[0-9x]+}grid_{step}step_{N}N__{name}_{tracktype}.pkl"
  output: pkl_b_file="bmaps/bmap_{grid_str,[0-9x]+}grid_{step}step_{N}N__{name}_{tracktype}.pkl"
  resources:
    mem_mb=800000
  run:
    b = load_pickle(input.b)
    bp = load_pickle(input.bp)
    bp.Bs = b.Bs
    bp.B_pos = b.B_pos
    bp.save(output.pkl_b_file)


# ---- save the fit data
rule save_data:
  # only get the data, e.g. for testing, for this model
  input: seqlens=files['seqlens'], recmap=files['recmap'],
         access=files['access'], fasta=files['fasta'],
         neut=files['neut'], counts_dir=join(files['counts'], data_path),
         bs_file=Bs_file
  output: "fits/pop_{popl}/window_{window}/type_{tracktype}/model_data.pkl"
  benchmark: "benchmarks/data_{popl}_{window}_{tracktype}.txt"
  resources:
    mem_mb=100000,
    time_min=300,
  shell:
    """
    bgspy data --seqlens {input.seqlens} --recmap {input.recmap} \
      --counts-dir {input.counts_dir} --neutral {input.neut} \
      --access {input.access} --bs-file {input.bs_file} \
      --window {wildcards.window} \
      --fasta {input.fasta} \
      --output {output}
    """

# ---- fit the MLE
rule fit:
  input: "fits/pop_{popl}/window_{window}/type_{tracktype}/model_data.pkl"
  output: "fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/initial/mle.pkl"
  params: **settings
  resources:
    mem_mb=80000,
    time_min=1980,
    threads=50
  benchmark: "benchmarks/fit_{popl}_{window}_{tracktype}_{mutrate}.txt"
  shell:
    """
    bgspy fit \
      --pi0-bounds {params.pi0_bounds} --mu-bounds {params.mu_bounds} \
      --mu {wildcards.mutrate} \
      --data {input} \
      --ncores {resources.threads} --nstarts {params.nstarts} \
      --output {output}
    """

# ---- predict subrates, etc
rule subrate_predict:
  input: fit="fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/initial/mle.pkl", 
         bs_file=Bs_file
  output: "fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/initial/predicted_subrates.tsv", 
  params: **settings
  resources:
    mem_mb=200000,
    time_min=980,
    threads=40
  shell:
    """
    bgspy subrate \
      --fit {input.fit} --bs-file {input.bs_file} \
      --ncores {resources.threads} --output {output}
    """

rule subrate_predict_mu_jk:
  input: fit="fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/{type}/jackknife/block_{blocksize}/jackknife_{frac}.pkl",
         bs_file=Bs_file
  output: "fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/{type}/jackknife/block_{blocksize}/predicted_subrates/jackknife_{frac}__{mu}.tsv"
  params: **settings
  resources:
    mem_mb=200000,
    time_min=980,
    threads=40
  shell:
    """
    bgspy subrate \
      --fit {input.fit} --bs-file {input.bs_file} --mu {wildcards.mu} \
      --ncores {resources.threads} --output {output}
    """

rule subrate_predict_mu:
  input: fit="fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/initial/mle.pkl", 
         bs_file=Bs_file
  output: "fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/initial/predicted_subrates_{mu}.tsv", 
  params: **settings
  resources:
    mem_mb=200000,
    time_min=980,
    threads=40
  shell:
    """
    bgspy subrate \
      --fit {input.fit} --bs-file {input.bs_file} --mu {wildcards.mu}\
      --ncores {resources.threads} --output {output}
    """


rule subrate_predict_rescale:
  input: fit="fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/rescaled/mle.pkl", 
         bs_file=Bs_file_rescaled
  output: "fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/rescaled/predicted_subrates.tsv", 
  params: **settings
  resources:
    mem_mb=200000,
    time_min=980,
    threads=50
  shell:
    """
    bgspy subrate \
      --fit {input.fit} --bs-file {input.bs_file} \
      --ncores {resources.threads} --output {output}
    """



# ---- jackknife
rule block_jackknife:
  # note that this doesn't actually require fit object, but 
  # I prefer that gets calculated first
  input: data="fits/pop_{popl}/window_{window}/type_{tracktype}/model_data.pkl",
         fit="fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/{type}/mle.pkl"
  output: "fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/{type}/jackknife/block_{blocksize}/jackknife_{frac}.pkl"
  params: **settings
  resources:
    mem_mb=10000,
    time_min=1000,
    threads=40
  shell:
    """
    bgspy jackblock \
      --blockwidth {wildcards.blocksize} \
      --data {input.data} \
      --mu {wildcards.mutrate} \
      --pi0-bounds {params.pi0_bounds} --mu-bounds {params.mu_bounds} \
      --output {output[0]} \
      --blockfrac {wildcards.frac} \
      --ncores {resources.threads} --nstarts {params.nstarts_jackknife}
    """


rule loo_chrom:
  # note that this doesn't actually require fit object, but 
  # I prefer that gets calculated first
  input: data="fits/pop_{popl}/window_{window}/type_{tracktype}/model_data.pkl",
         fit="fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/initial/mle.pkl"
  output: "fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/initial/loo_chrom/loo_{chrom}.pkl"
  params: **settings
  resources:
    mem_mb=10000,
    time_min=1000,
    threads=40
  shell:
    """
    bgspy loo \
      --data {input.data} \
      --output {output} \
      --mu {wildcards.mutrate} \
      --pi0-bounds {params.pi0_bounds} --mu-bounds {params.mu_bounds} \
      --chrom {wildcards.chrom} \
      --ncores {resources.threads} --nstarts {params.nstarts_loo}
    """

rule loo_chrom_rescale:
  # note that this doesn't actually require fit object, but 
  # I prefer that gets calculated first
  # -- this one is only different because we widen parameters for rescale
  input: data="fits/pop_{popl}/window_{window}/type_{tracktype}/model_data.pkl",
         fit="fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/rescaled/mle.pkl"
  output: "fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/rescaled/loo_chrom/loo_{chrom}.pkl"
  params: **settings
  resources:
    mem_mb=10000,
    time_min=1000,
    threads=40
  shell:
    """
    bgspy loo \
      --data {input.data} \
      --output {output} \
      --mu {wildcards.mutrate} \
      --pi0-bounds {params.pi0_bounds} --mu-bounds {params.mu_bounds_rescale} \
      --chrom {wildcards.chrom} \
      --ncores {resources.threads} --nstarts {params.nstarts_loo}
    """


# ----- locally-rescaled fits -----

rule save_data_rescale:
  input: seqlens=files['seqlens'], recmap=files['recmap'],
         access=files['access'], fasta=files['fasta'],
         neut=files['neut'], counts_dir=join(files['counts'], data_path),
         bs_file=Bs_file_rescaled
  output: "fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/rescaled/model_data_rescaled.pkl"
  params: name=name
  resources:
    mem_mb=200000,
    time_min=300
  shell:
    """
    bgspy data --seqlens {input.seqlens} --recmap {input.recmap} \
      --counts-dir {input.counts_dir} --neutral {input.neut} \
      --access {input.access} --bs-file {input.bs_file} \
      --window {wildcards.window} \
      --fasta {input.fasta} \
      --output {output}
    """

rule fit_rescaled:
  input: "fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/rescaled/model_data_rescaled.pkl"
  output: "fits/pop_{popl}/window_{window}/type_{tracktype}/mutrate_{mutrate}/rescaled/mle.pkl"
  params: **settings
  benchmark: "benchmarks/fit_{popl}_{window}_{tracktype}_{mutrate}_rescaled.txt"
  resources:
    mem_mb=60000,
    time_min=980,
    threads=50
  shell:
    """
    bgspy fit \
      --pi0-bounds {params.pi0_bounds} --mu-bounds {params.mu_bounds_rescale} \
      --mu {wildcards.mutrate} \
      --data {input} \
      --ncores {resources.threads} --nstarts {params.nstarts} \
      --output {output} --only-Bp
    """


## ----- CLI rules 
rule tracks: 
  input: f"tracks/{name}_full.bed.gz", f"tracks/{name}_sparse.bed.gz"

rule data:
  input: model_data

rule mle:
  input: mle_fits

rule jackknife:
  input: mle_fits, jackknife_fits

rule loo:
  input: mle_fits, loo_fits

#rule rescaled:
#  input: mle_results_rescaled

rule predict:
   input: preds

rule all:
  input: model_data, mle_fits, jackknife_fits, loo_fits, preds


