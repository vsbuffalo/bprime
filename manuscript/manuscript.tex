\documentclass[11pt]{article}
\RequirePackage{fullpage}
\RequirePackage[font=small,labelfont=bf]{caption}
\RequirePackage{amsmath,amssymb,amsthm}
\RequirePackage{graphicx}
\RequirePackage[hidelinks]{hyperref}
\RequirePackage{subcaption}
\RequirePackage{wasysym}
\RequirePackage{authblk}
\RequirePackage{bm}
\RequirePackage{bbm}
\RequirePackage[osf]{mathpazo}
\RequirePackage[bibstyle=authoryear,citestyle=authoryear-comp,
                date=year,
                maxbibnames=9,maxnames=5,maxcitenames=2,
                backend=biber,uniquelist=false,uniquename=false,
                % style=apa,
                sorting=nyt,
                % sorting=,
                hyperref=true]{biblatex}
\usepackage{color}
\usepackage{nicefrac}

\renewcommand{\P}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\V}{\text{V}}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\cov}{cov}

\addbibresource{biblio.bib}

\title{}

\author{Vince Buffalo and Andrew Kern}

\begin{document}
\maketitle

% A central goal of evolutionary genetics is to quantify the relative roles
% different evolutionary processes have on genetic variation. Certain
% evolutionary processes, such as demographic bottlenecks or expansions, act
% uniformly across the genome as a whole. Other processes, such as selection, are
% hypothesized to act differently across the genome depending on the density of
% genomic features, and local heterogeneity in recombination and mutation rate.
% With the emergence of population genomic data, a variety of statistical models
% have teased apart the contribution of these various processes. These
% statistical models differ in how they reduce large genomic data to summary
% statistics, as well as in their statistical methodology. Some models reduce
% genomic data to the histograms of the frequency spectrum (XXX), while others
% model scalar summaries of the frequency spectrum along the genome. 

% One class of models, parametric statistical models, leverage population genetic
% theory to inform expectations of the mean pairwise diversity along the
% chromosome. Estimation under these models often uses a composite likelihood
% approach, where the joint distribution is assumed independent across positions.
% While composite likelihoods are simpler to formulate and lead to consistent
% parameter estimation, ignoring dependencies between neighboring sites has two
% primary disadvantages. First, unlike proper likelihoods, the composite
% likelihood's curvature is uninformative about parameter estimate uncertainty.
% Previous work has circumvented this shortcoming through (1) resampling-based
% uncertainty estimates, or (2) adjusting the composite likelihood's curvature to
% account for these dependencies. Second, similar to inference under phylogenetic
% comparative models, the dependency structure tells us how to properly weight
% information across sites. For example, imagine a conserved segment 10 kilobases
% long right on the border of two genomic bins, which due to linked selection,
% bot experience a reduction in diversity. When estimating parameters, the
% independence assumption of composite likelihoods would weight these observed
% reductions equal to the amount of a reduction observed on an entirely different
% independent chromosome. 

% patterns of genetic variability along the genome are treated as
% coming from an indeprocess $m(z)$.


% Here, we focus on solving an issue processes: background

% BGS as evolution around the static features of the genome. Due to the slow rate
% of genomic structural evolution, much of the genome can be treated as static
% throughout the genome. These regions are under differing levels of selective
% constraint, which induces background selection at neighboring regions.


% Signal processing

% Genomes have inherent structure that impacts the linked selection map. There is
% tremendous heterogeneity across species in the organization of likely selected
% regions on the genetic and physical maps.

% Within an organism, there are two key determinants of B maps: recombination and
% gene density. 

% Initially, the relationship between recombination and diversity was regressed
% with no regard to the spatial organization of the genome.

% Certain regions are pinchpoints of selection: some combination of low
% recombination and high gene density lead to very strong reductions in genetic
% diversity. In these regions, coalescent dynamics change considerably; where as
% under strong background selection, deleterious alleles would not fix, in these
% regions the can fix. Additionally, the selective interference impacts positive
% selection.

- Disentangling evolutionary processes from the patterns of genetic variation
across the genome. The structure of what can be under selection shapes these
patterns when selection acts; when drift acts, these patterns should not exist.

- For species with small effective population sizes (and perhaps large map
lengths), BGS seems to be a dominant selective force in shaping patterns of
diversity (e.g. at the megabase scale in humans).

- However, current approaches to fitting BGS models fail under the weak
selection domain. This weak selection domain is important (discuss
HRI/ratchet/etc). Importantly, the characteristic scale of the impact of linked
selection is $\nicefrac{s}{r}$, meaning weak selection acts on smaller scales
than strong selection. Our ability to see selection at small scales may be
inhibited by the fact that our current BGS theory only works for strong
selection.

- We need to say briefly that we're using BGS to mean linked selection due to
purifying selection, and thus the strong and weak regimes (classically it has
just meant the strong regime).

\section*{Theory}

There has been considerable past work to find both the rate of the ratchet
(XXX), and summaries of the genealogies created under weak purifying selection
(XXX). Our approximation combines a few theoretic avenues from past work. Our
primary goal is to find a theoretic scaling function $B$ that rescales the neutral
pairwise coalescent times the appropriate amount to 

Strictly speaking, there is no way to rescale the coalescent under general
background selection process, as genealogies deviate from the Kingman
coalescent slightly under strong selection
\parencite{Walczak2012-fi,Cvijovic2018-vd} and greatly under weak selection
\parencite{OFallon2010-my}

First, we approximate the coalescent effective population size, which
determines expected pairwise diversity, from the variance effective population
size. Then, we use a general quantitative genetic model of linked selection to
find the variance effective population size under background selection. Since
the impact of selection under this model is parameterized by the additive
genetic fitness variance, we use an approximation for this based on the
additive \emph{genic} variance, which depends on the rate of the ratchet.
Previous work has been unable to find a simple closed-form solution to the rate
of the ratchet because it depends on moments of the fitness distribution (e.g.
fitness variation), which in turn depend on even higher-moments of the fitness
distribution (e.g. the skew of the fitness distribution). While the ratchet
should scale with the probability of fixation, the probability of fixation
(Kimura, Malecot, XXX) is not accurate when multiple deleterious mutations are
segregating simultaneously and in close linkage with one another. A key insight
of \textcite{Santiago2016-mu} was that the classic equation for the probability
of fixation is fairly robust as long as the correct effective population size
is used. Their approach is to solve a system of two non-linear equations: one
for the variance effective population size (which depends on the rate of the
ratchet), and another for the time to fixation (which depends on the effective
population size).

Below, we step through the theory we use in our statistical methods. We
re-derive central parts to illustrate where approximations have been made,
which allows us to understand how these approximations may impact our
statistical methods and inspect model fit in regions where these approximations
are less likely to hold.

\subsection*{Pairwise Diversity under Background Selection}

The central quantity of interest for our statistical inference methods is
average pairwise diversity along the chromosome. While other summaries of the
data, such as the allele frequency spectrum, may be more informative about the
evolutionary processes acting in a region, we lack population genetic theory
for these quantities under most selective regimes and they require more degrees
of freedom to characterize. By contrast, neutral diversity under an
infinite-sites model is determined only by the per-basepair mutation rate $\mu$
and the expected pairwise coalescent time $\E[T_2]$,

\begin{align}
  \E(\pi) = 2 \mu \E(T_2)
\end{align}

Let us assume that there is a constant \emph{drift-effective} population size
$N_d$ which determines the rate of coalescence due only to neutral demographic
processes. Additionally, we assume some background selection process that in
expectation rescales the drift-effective population size by $b(t)$ at time $t$
(though this could be any process that modifies the coalescence rate). Then,
the expected pairwise coalescent time is

\begin{align}
  \E(T_2) = \sum_{i=1}^\infty \frac{i}{2 b(t) N_d}\prod_{t=1}^{i-1} \left(1-\frac{1}{2 b(t) N_d}\right).
\end{align}

The time-dependency of $b(t)$ is needed because coalescence rates essentially
speed up in the past under intermediate to weak selection, similar to
population growth \parencite{Walczak2012-fi,Seger2010-rs,Good2014-yz}.
Intuitively, this is because lineages are unlikely to coalesce with numerous
less fit lineages they encounter as they go back in time, until ultimately
coalescing in one of the least-loaded fitness classes. 

Previous work in the strong background selection domain
\parencite{Charlesworth1993-gb,Nordborg1996-nq} approximates $\E(T_2)$ as $2
f_0 N_d$, where $f_0 = e^{-\nicefrac{U}{s}}$ is size of the least-loaded
fitness class. XXX on delay

Here, we model the background selection process forward in time. We approximate
the expected pairwise diversity with the probability of heterozygosity,
$\E(\pi) \approx \mathcal{H}$, which holds under weak mutation and random
mating, such that

\begin{align}
  %\mathcal{H} =  2 \mu \sum_{i=1}^\infty \prod_{t=1}^i \left(1-\frac{1}{2 b(t) N_d} \right)
  \mathcal{H} &= 1 - \sum_{i=1}^\infty (1-\mu)^{2i} \prod_{t=1}^i \left(1-\frac{1}{2 b(t) N_d} \right) \\
              &\approx 2 \mu \sum_{i=1}^\infty \prod_{t=1}^i \left(1-\frac{1}{2 b(t) N_d} \right)
\end{align}

in the limit where $\mu \to 0$. This is equation 4 of
\textcite{Santiago2016-mu}; they define the sum as the heterozygosity effective
population size.

\subsection*{Forward in Time Models of Background Selection}

Next, show how quantitative genetic models of linked selection
\parencite{Robertson1961-ho,Santiago1995-hx,Santiago1998-bs,Santiago2016-mu}
model $b(t)$ forward in time.

\begin{align}
  b(t) = \frac{N_v}{N_d}
\end{align}

where

\begin{align}
  N_v = \lim_{t \to \infty} \frac{p_0 (1 - p_0) - \var(p_{t-1})}{2\var(p_t) - \var(p_{t-1})}
\end{align}

\subsection*{Linked Selection Models for Variance-Effective Population Size}

We wish to derive an expression for the reduction factor $B$. Ideally, this
reduction factor would rescale the coalescent-effective population size, but
this would require knowing the coalescent rate function $\lambda(t)$ over the
evolutionary history $0 < t < \infty$. Instead, following previous work
\parencite{Santiago1995-hx,Santiago1998-bs}, we derive the rescaling function
$B$ relative to the variance-effective population size.

Following past quantitative genetic models of linked selection
\parencite{Robertson1961-ho,Santiago1995-hx,Santiago1998-bs,Santiago2016-mu},
we consider the long-run variance effective population size, 

\begin{align}
  N_v := \lim_{t \to \infty} \frac{p_0(1-p_0)}{2\var\left(p_t - p_0\right)}
\end{align}





% ADD TO INTRO TODO
Comment about characteristic scale $\nicefrac{\mu}{s}$. Is the fact that we see
BGS on megabase scales because this is the only scale we can detect strong
selection under?


approximately $\pi \approx 4N_e \mu$ (for low mutation rate). However, this
assumes a constant Kingman coalescent with coalescent effective population size
$N_e$. 

\subsection*{}

We model the reduction in pairwise coalescence times along the genome due to
background selection by extending the work of \textcite{Santiago2016-mu}
(hereafter, the SC16 model). The SC16 model derives from a class of linked
selection \parencite{Robertson1961-ho,Santiago1995-hx,Santiago1998-bs} that
predict the reduction in pairwise coalescence time at a focal neutral site
using macro-state parameters such as fitness variation, rather than micro-state
parameters like the frequency trajectories of selected alleles (e.g.
\textcite{Maynard_Smith1974-zr}). We will briefly introduce the SC16 model's
approach and how we validated this model could be extended to whole-genome
inference.

Classic background selection theory models how coalescence times are reduced by
deleterious mutation-selection balance at neighboring sites. Building upon
older models of genetic load \parencite{Crow1970-wj,Kimura1966-bk}, these
models consider the equilibrium distribution of the \emph{number} of
deleterious mutations segregating on haplotypes
\parencite{Charlesworth1993-gb,Nordborg1996-nq}. Given an infinitely large
population, or sufficiently strong selection, the deleterious mutations in
these models cannot fix; consequently, any lineage containing 

While the effect of selection on linked selection distorts neighboring
genealogies (XXX), skewing the site frequency spectrum (XXX) and altering
linkage disequilibria along the chromosome, we focus on the impact of selection
on pairwise coalescence rates. This simple summary is amenable to mathematical
and statistical inference, and is robust to difficulties in identifying rare
variants. The effect of background selection on pairwise coalescence rates is
expressed as the reduction ratio $B = \nicefrac{N_e}{N}$ where $N$ is the
drift-effective population size (i.e. including demographic processes) and
$N_e$ is the effective population size under background selection.

Under quantitative genetic models of linked selection, the reduction in
effective population size is determined by the product of fitness variation,
$V_f$, and an inflation factor $Q$. It is helpful to understand this by comparing
it to a model of $N_e$ without \emph{heritable} fitness variation but with
\emph{non-heritable} fitness variation. In this case, 

\begin{align}
  N_e = \frac{4N}{2 + V_k},
\end{align}

where $V_k$ is the variance in offspring number across individuals. Under a
constant population size Wright--Fisher model of reproduction, $V_k \approx 2$,
and this simplifies to $N_e = N$. However, as first noted by
\textcite{Robertson1961-ho}, linked selection inflates the variance in
offspring number, as a neutral allele that becomes associated with a
high-fitness or low-fitness genetic background has an $1-r$ chance of remaining
associated with that background in the next generation, where $r$ is the chance
of recombination (or independent assortment, $r=\nicefrac{1}{2}$). 


This persistence of this association inflates the effective variance in fitness
by a factory $Q^2$, 

\begin{align}
  N_e = \frac{4N}{2 + V_k + 4 Q^2 V_f},
\end{align}


\begin{align}
  N_e = \frac{4N}{2 + V_k + 4 Q(r)^2 V_f},
\end{align}




\begin{align}
  N_e = N \exp\left(-Q^2 V_f\right)
\end{align}

In a region of $L$ basepairs under purifying selection, there is a net flux of
deleterious mutations in at rate $U = 2 \mu L$ per generation (where the factor
of two is because in diploids, $2L$ is the total number of basepairs per genome). 

Typical models of background selection consider the equilibrium distribution of
the \emph{count} of deleterious mutations, rather than then level of fitness
variation implied by this count. If we assume fixed additive effects across
alleles and multiplicative fitness effects across loci, each copy of a
deleterious mutation an individual carries reduces their fitness by a factor of
$1-s$. The total reduction for an individual is

\begin{align}
  x = (1-s)^n
\end{align}

where $n$ is the number of deleterious alleles an individual carries. Under
mutation-selection balance, the population evolves to either a stationary
distribution under the strong BGS domain, or a traveling distribution in weak
selection case. Under some assumptions, equilibrium models of the strong domain
show that the distribution $f(n) \sim \text{Pois}(\nicefrac{U}{s})$
\parencite{Kimura1966-bk,Crow1970-wj} (CHECK) in the asexual case, and the
fixation rate of deleterious mutations per generation, or ratchet rate, is $R =
0$ since the probability of fixation, $p_F$ is zero. By contrast, as the
selection coefficient grows weaker, $s \to 0$, the probability of fixation $p_F
\to \nicefrac{1}{2N}$, and the ratchet approaches the neutral rate of $R =
\mu$. The weak selection domain is of importance because both because it
implies a certain likely irreversible rate of fitness reduction, and because it
could possibly confound population genetic inference which assumes dynamics
only under the strong model.

As $s \to 0$, the fitness distribution, put on a scale reflecting the fitness
relative at one moment in time, travels leftwards and changes shape. It has
been difficult to find dynamic equations for the rate of the ratchet and
fitness distribution, since lower moments of the distribution, such as the
variation, depend on higher moments, such as the skew
\parencite{Good2013-lp,Haigh1978-gt,Higgs1995-xc}. This is known as the ``moment
closure problem" and it occurs regardless of whether one models the count
number of deleterious mutations (XXX) or the fitness distribution (XXX).

We can approximate the mapping between the distribution of deleterious
mutations in the population, and the fitness distribution. It is worth noting
that the count of deleterious mutations in an individual $i$ can be written
$n_i = \sum_l^{L} g_l$ where each $g_l$ is an indicator variable for whether
the individual carries a mutation at position $l$. Then, $\V_i(n) = \sum_l
\V(g_l) + \sum_{i,j}\cov(g_i, g_j)$.

the
number of deleterious mutations in gamete $i$; thus $V(n) = \sum_i^{2N} V(x_i)
+ \sum_{i \ne j} \cov(x_i, x_j)$ where the last term is the correlation among
gamete mutation counts, which is an LD quantity. Then, assuming $s$ is small,
we can write express this in terms of the additive genetic variance, 

\begin{align}
  V(f) &\approx s^2 \V_a(n) + \delta_\text{LD}
\end{align}

The first term is the additive genic variance, which is 


Under this model, the rate of the ratchet $R = U  - s V(n)$, which implies,

\begin{align}
  R = U - \nicefrac{V(f)}{s} \\
  V(f) = s(U - R)
\end{align}



Throughout, it's worthwhile to keep into mind many population-level
macro-states are simply distributional summaries of the current population. For
example, the variance in deleterious mutations in the population is simply,
$\V(n) = \nicefrac{1}{2N} \sum_i (x_i - \mu_x)^2$





- We need to mention the two heterozygosities (S\&C '16 says they diverge under
$N_e s < 1$ -- could explain anything we see?)

- A point about reconciling the two micro and macro-state theories of
population and quantitative genetics.





\subsection*{The Rate of the Ratchet}


\section*{Methods}

\subsection*{Data Preprocessing}

\subsection*{Human}

Site-level neutral and accessibility masks

Bin-level masks based on fraction of accessible bases in a window (7\%).

Bin-level tail filtering.

\printbibliography

\end{document}
